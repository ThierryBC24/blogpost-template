---
layout: post
title: Milestone 2
---
# Ingénérie des données

## Question 1

## Modèles simples


On remarque une précision d'eniron 90 % avec un modèle de régression logistique entrainé avec la caractéristique de distance. Si 90 % des tirs ne sont pas des buts, un modèle naïf pourrait obtenir une précision de 90 % simplement en prédisant toujours "non-buts". Cependant, ce modèle manquerait complètement de pertinence pour prédire des buts. On pourrait utiliser des métriques comme la précision pour chaque classe, le rappel (recall), le F1-score ou l'AUC-ROC pour évaluer la performance globale.  

![Accuracy](/images/accuracy.png)



Les graphiques révèlent que les performances d'une régression logistique basée sur les probabilités de marquer un but sont légèrement supérieures à celles d'un classifieur aléatoire. Cependant, cette amélioration reste marginale. Le classifieur entraîné avec les deux caractéristiques principales, la distance et l'angle de tir, affiche une AUC de 0,56, contre 0,50 pour le classifieur aléatoire. Ces résultats suggèrent que la distance et l'angle sont des variables pertinentes qui contribuent à différencier les situations de tir. Individuellement, la distance atteint également une AUC de 0,56, tandis que l'angle seul présente une AUC de 0,54.

En examinant la fiabilité, le diagramme de calibration montre que les prédictions du modèle sont mal calibrées : les probabilités prédites ne correspondent pas toujours à la fréquence observée des buts. Cela signifie que même si la distance et l'angle aident à discriminer les tirs, le modèle a tendance à surestimer ou sous-estimer les probabilités dans certains intervalles. Par ailleurs, les graphiques de taux de buts par centile et de proportion cumulée des buts indiquent que le modèle est légèrement meilleur que l'aléatoire pour identifier des situations avec une probabilité plus élevée de but.
 

![Dataframe](/images/plots/ROC.png)  

![Dataframe](/images/plots/Goal_rate.png)  

![Dataframe](/images/plots/Buts_cummules.png)

![Dataframe](/images/plots/diagramme_fiabilite.png)  

Liens vers les modèles  
[Angle](https://wandb.ai/IFT67582024-A07/Logistic%20Regression%20Angle?nw=nwuserphilippebergeron7)  
[Distance + Angle](https://wandb.ai/IFT67582024-A07/Logistic%20Regression%20Distance%20Angle?nw=nwuserphilippebergeron7)  
[Distance](https://wandb.ai/IFT67582024-A07/Logistic%20Regression%20Distance?nw=nwuserphilippebergeron7)

## Modèles avancés

### Question 1
![Dataframe](/images/plots/advanced_roc.png)  

![Dataframe](/images/plots/advanced_goal_rate.png)  

![Dataframe](/images/plots/advanced_cummulated.png)  

![Dataframe](/images/plots/advanced_calibration.png)  

Les données d'entrée, composées de la distance et de l'angle des tirs, ont été divisées en un ensemble d'entraînement (80 %) et un ensemble de validation (20 %) de manière aléatoire. Le modèle utilisé est XGBoost, configuré avec des paramètres spécifiques : 100 arbres (n_estimators), un taux d'apprentissage (learning_rate) de 0,1, une profondeur maximale (max_depth) de 6, et un sous-échantillonnage (subsample) de 1.

XGBoost a montré des performances globalement meilleures que la régression logistique, avec une AUC de 0,62 contre 0,57 pour cette dernière, démontrant une meilleure capacité à différencier les buts des non-buts. Les graphiques générés, tels que la courbe ROC et la proportion cumulée des buts, confirment que XGBoost capture efficacement les situations à forte probabilité de but, surpassant ainsi la régression logistique et un modèle aléatoire.

Le graphique du taux de buts par centile a révélé que XGBoost identifie mieux les zones à haute probabilité de but, bien que le déséquilibre des classes dans les données reste visible. De plus, la proportion cumulée des buts montre que XGBoost est capable de capturer une proportion significative des buts dans les premiers centiles.

### Question 2

Toutes les caractéristqiues créées à la partie 4 sont utilisés.
La recherche par grille avec validation croisée a été utilisé pour chercher les meilleurs hyperparamètres. La grille est composée de valeur au dessus et en dessous des valeurs par défaut.

![Dataframe](/images/grid.png)  

![Dataframe](/images/grid_search_result.png)  
Ces hyperparamètres ont été utilisés pour contruire un nouveau modèle XGBoost.  


En comparant les résultats du modèle XGBoost avec toutes les caractéristiques disponibles à ceux obtenus avec le modèle de base dans la question 1, une amélioration significative de la performance est observée. Le modèle de base, utilisant uniquement les caractéristiques de distance et d'angle, a obtenu une AUC de 0,62. Avec l'ajout de toutes les caractéristiques pertinentes, l'AUC passe à 0,77.

Le graphique du taux de buts par centile montre que le modèle enrichi est plus efficace pour identifier les situations à forte probabilité de but, capturant une plus grande proportion de buts dans les centiles supérieurs de la probabilité prédite. En comparaison, le modèle de base, utilisant uniquement la distance et l'angle, présentait des performances proches d'un modèle aléatoire et avait une capacité réduite à prédire les tirs à fort potentiel de but. Le graphique de la proportion cumulée des buts révèle que le modèle XGBoost avec toutes les caractéristiques surperforme également le modèle de base, capturant davantage de buts dans les premiers centiles de probabilité. Enfin, le diagramme de fiabilité montre que le modèle enrichi est mieux calibré, avec une meilleure correspondance entre les probabilités prédites et les fréquences observées des buts, bien que la calibration reste imparfaite, en particulier dans les intervalles extrêmes.

Cette amélioration reflète la capacité de XGBoost à exploiter efficacement l'information supplémentaire pour capturer des relations plus complexes entre les données. Les résultats montrent que les nouvelles caractéristiques contribuent à enrichir la capacité prédictive du modèle, augmentant ainsi sa précision globale.


![Dataframe](/images/plots/all_features_roc.png)  

![Dataframe](/images/plots/all_features_goal_rate.png)  

![Dataframe](/images/plots/all_features_cummulated.png)  

![Dataframe](/images/plots/all_features_calibration.png)  

Lien vers modèle:  
[Tout caractéristiques](https://wandb.ai/orgs/philippe-bergeron-7-universit-de-montr-al-org/registry/model?selectionPath=philippe-bergeron-7-universit-de-montr-al-org%2Fwandb-registry-model%2FXGBoost&view=membership&tab=overview&version=v1)

### Question 3

![Dataframe](/images/shap.png)  

Pour sélectionner les caractéristiques les plus pertinentes, l’outil SHAP (SHapley Additive exPlanations), qui permet d’évaluer l’impact de chaque caractéristique sur les prédictions du modèle XGBoost a été utilisé. SHAP attribue une valeur d’importance à chaque caractéristique, en quantifiant sa contribution positive ou négative à chaque prédiction, ce qui aide à identifier les caractéristques importantes influençant les résultats.

Initialement, toutes les caractéristiques disponibles ont été incluses dans le modèle XGBoost pour établir une performance de référence. Ensuite, SHAP a été appliqué pour analyser l’importance relative des caractéristiques. Les résultats ont montré que la distance du tir et l’angle du tir sont les plus influentes dans les prédictions, confirmant leur pertinence déjà observée dans des approches précédentes. D’autres variables, telles que le type de tir et le temps de jeu, ont également été identifiées comme pertinentes.

Sur la base des résultats de SHAP, un sous-ensemble de caractéristiques a été proposé, comprenant les variables les plus significatives identifiées par l’analyse. En comparant les performances avec ce sous-ensemble optimisé, le modèle a démontré une AUC légèrement inférieure par rapport à l’ensemble complet de caractéristiques (0,76 contre 0,77), mais une complexité réduite, ce qui pourrait être avantageux dans des scénarios où les ressources computationnelles ou l’interprétabilité sont critiques.

Les hyperparamètres suivant ont été choisis en fonction de la sélection des caractéristiques: 

![Dataframe](/images/sel_parameters.png) 

En conclusion, l’utilisation de SHAP a permis de prioriser les caractéristiques et d’explorer des modèles simplifiés sans sacrifier de manière significative les performances. L’ensemble optimal de caractéristiques comprend la distance, l’angle, les types de tirs, le temps de jeu et le temps de pression offensif, qui, ensemble, capturent les relations essentielles entre les données et les résultats.

![Dataframe](/images/shap_sel.png)  

Les courbes du modèle simplifié:  

![Dataframe](/images/plots/sel_roc.png)  

![Dataframe](/images/plots/sel_goal_rat.png)  

![Dataframe](/images/plots/sel_cummulated.png)  

![Dataframe](/images/plots/sel_calibration.png)  

Lien vers modèle:  
[Simplifié](https://wandb.ai/orgs/philippe-bergeron-7-universit-de-montr-al-org/registry/model?selectionPath=philippe-bergeron-7-universit-de-montr-al-org%2Fwandb-registry-model%2FXGBoost&view=membership&version=v2)


